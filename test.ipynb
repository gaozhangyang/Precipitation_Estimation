{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Indicator\" data-toc-modified-id=\"Indicator-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Indicator</a></span></li><li><span><a href=\"#Dataloader\" data-toc-modified-id=\"Dataloader-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Dataloader</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Indicator:\n",
    "    def __init__(self):\n",
    "        self.y_true=[]\n",
    "        self.y_pred=[]\n",
    "        \n",
    "    def indicator_cls(self):\n",
    "        tn, fp, fn, tp=confusion_matrix(self.y_true,self.y_pred ).ravel()\n",
    "        POD=tp/(tp+fn)\n",
    "        FAR=fp/(tp+fp)\n",
    "        CSI=tp/(tp+fn+fp)\n",
    "        return {'POD':POD,'FAR':FAR,'CSI':CSI}\n",
    "    \n",
    "    def indicator_reg(self):\n",
    "        conv=np.cov([self.y_true,self.y_pred])\n",
    "        CC=conv[0,1]/np.sqrt(conv[0,0]*conv[1,1])\n",
    "        BIAS=np.sum(np.array(self.y_pred)-np.array(self.y_true))/np.sum(self.y_true)\n",
    "        MSE=np.mean((np.array(self.y_pred)-np.array(self.y_true))**2)\n",
    "        return {'CC':CC,'BIAS':BIAS,'MSE':MSE}\n",
    "    \n",
    "    def reset(self):\n",
    "        self.y_true=[]\n",
    "        self.y_pred=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POD': 0.5, 'FAR': 0.0, 'CSI': 0.5}\n",
      "{'CC': 0.5219991862216652, 'BIAS': -0.16938088345983845, 'MSE': 0.08807572443283634}\n"
     ]
    }
   ],
   "source": [
    "indicator=Indicator()\n",
    "\n",
    "y_true=np.array([0,1,0,1])\n",
    "y_pred=np.array([0,0,0,1])\n",
    "indicator.y_true.extend(y_true.tolist())\n",
    "indicator.y_pred.extend(y_pred.tolist())\n",
    "print(indicator.indicator_cls())\n",
    "indicator.reset()\n",
    "\n",
    "y_true=np.random.rand(10)\n",
    "y_pred=np.random.rand(10)\n",
    "indicator.y_true.extend(y_true.tolist())\n",
    "indicator.y_pred.extend(y_pred.tolist())\n",
    "print(indicator.indicator_reg())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275\n"
     ]
    }
   ],
   "source": [
    "start_date = date(2011, 12, 31)\n",
    "end_date = date(2012, 10, 1)\n",
    "diff=end_date-start_date\n",
    "print(diff.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T04:54:01.414440Z",
     "start_time": "2020-07-17T04:52:25.811472Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "GOSE=np.load('/usr/commondata/weather/IR_data/IR_dataset_QingHua/X_train_hourly.npz')\n",
    "StageIV=np.load('/usr/commondata/weather/IR_data/IR_dataset_QingHua/Y_train_hourly.npz')\n",
    "GOSE=GOSE['arr_0']\n",
    "StageIV=StageIV['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class IRDataset(Dataset):\n",
    "    def __init__(self,task='identification',mode='train',shuffle=False,win_size=14):\n",
    "        self.X=GOSE\n",
    "        self.Y=StageIV\n",
    "        self.win_size=win_size\n",
    "        self.R_samples,self.NR_samples=self.split_R_NR(self.Y)\n",
    "        \n",
    "        \n",
    "        if task=='identification':\n",
    "            self.samples=np.vstack([np.array(random.choices(self.R_samples,k=340000)),\n",
    "                                    np.array(random.choices(self.NR_samples,k=340000))])\n",
    "        \n",
    "        if task=='estimation':\n",
    "            self.samples=np.array(random.choices(self.R_samples,k=470000))\n",
    "        \n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.samples)\n",
    "        L=len(self.samples)\n",
    "        \n",
    "        \n",
    "        self.mode=mode\n",
    "        if mode=='train':\n",
    "            self.sample_idx=range(0,int(L*0.6))\n",
    "        \n",
    "        if mode=='test':\n",
    "            self.sample_idx=range(int(L*0.6),int(L*0.8))\n",
    "        \n",
    "        if mode=='val':\n",
    "            self.sample_idx=range(int(L*0.8),int(L*1))\n",
    "        \n",
    "        self.L=len(self.sample_idx)\n",
    "\n",
    "    \n",
    "    def safe_crop_center(self,img,x,y,cropx,cropy):\n",
    "        startx = x-(cropx)\n",
    "        endx=x+(cropx)+1\n",
    "        starty = y-(cropy)   \n",
    "        endy= y+(cropy)+1  \n",
    "        \n",
    "        if len(img.shape)==3:\n",
    "            _,H,W=img.shape\n",
    "            if startx<0 or starty<0 or endx>=H or endy>=H:\n",
    "                return None\n",
    "            return img[:,startx:endx,starty:endy]\n",
    "            \n",
    "        if len(img.shape)==2:\n",
    "            H,W=img.shape\n",
    "            if startx<0 or starty<0 or endx>=H or endy>=H:\n",
    "                return None\n",
    "            return img[startx:endx,starty:endy]\n",
    "    \n",
    "\n",
    "    def unsafe_crop_center(self,img,x,y,cropx,cropy):\n",
    "        startx = x-(cropx)\n",
    "        endx=x+(cropx)+1\n",
    "        starty = y-(cropy)   \n",
    "        endy= y+(cropy)+1\n",
    "        if len(img.shape)==2:\n",
    "            return img[startx:endx,starty:endy]\n",
    "        \n",
    "        if len(img.shape)==3:\n",
    "            return img[:,startx:endx,starty:endy]\n",
    "    \n",
    "    \n",
    "    def split_R_NR(self,StageIV):\n",
    "        R_samples=[]\n",
    "        NR_samples=[]\n",
    "        for T in range(StageIV.shape[0]):\n",
    "            for row in range(self.win_size,StageIV.shape[1]-self.win_size,self.win_size):\n",
    "                for col in range(self.win_size,StageIV.shape[2]-self.win_size,self.win_size):\n",
    "                    if StageIV[T,row,col]>0.1:\n",
    "                        R_samples.append((T,row,col))\n",
    "                    else:\n",
    "                        NR_samples.append((T,row,col))\n",
    "                        \n",
    "        R_samples=np.array(R_samples)\n",
    "        NR_samples=np.array(NR_samples)\n",
    "        return R_samples,NR_samples\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        T,row,col=self.samples[idx]\n",
    "        X_croped=self.unsafe_crop_center(self.X[T],row,col,self.win_size,self.win_size)\n",
    "        Y_croped=self.Y[T,row,col]\n",
    "        return X_croped,Y_croped,T,row,col\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.L\n",
    "\n",
    "    def name(self):\n",
    "        return 'IRDataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=IRDataset(mode='train',shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 29, 29) 0.0 32 182 336\n"
     ]
    }
   ],
   "source": [
    "X_croped,Y_croped,T,row,col=dataset[0]\n",
    "print(X_croped.shape,Y_croped,T,row,col)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate",
   "language": "python",
   "name": "climate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
