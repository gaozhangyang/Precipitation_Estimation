{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Indicator\" data-toc-modified-id=\"Indicator-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Indicator</a></span></li><li><span><a href=\"#Dataloader\" data-toc-modified-id=\"Dataloader-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Dataloader</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Indicator:\n",
    "    def __init__(self):\n",
    "        self.y_true=[]\n",
    "        self.y_pred=[]\n",
    "        \n",
    "    def indicator_cls(self):\n",
    "        tn, fp, fn, tp=confusion_matrix(self.y_true,self.y_pred ).ravel()\n",
    "        POD=tp/(tp+fn)\n",
    "        FAR=fp/(tp+fp)\n",
    "        CSI=tp/(tp+fn+fp)\n",
    "        return {'POD':POD,'FAR':FAR,'CSI':CSI}\n",
    "    \n",
    "    def indicator_reg(self):\n",
    "        conv=np.cov([self.y_true,self.y_pred])\n",
    "        CC=conv[0,1]/np.sqrt(conv[0,0]*conv[1,1])\n",
    "        BIAS=np.sum(np.array(self.y_pred)-np.array(self.y_true))/np.sum(self.y_true)\n",
    "        MSE=np.mean((np.array(self.y_pred)-np.array(self.y_true))**2)\n",
    "        return {'CC':CC,'BIAS':BIAS,'MSE':MSE}\n",
    "    \n",
    "    def reset(self):\n",
    "        self.y_true=[]\n",
    "        self.y_pred=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POD': 0.5, 'FAR': 0.0, 'CSI': 0.5}\n",
      "{'CC': 0.3769509070511113, 'BIAS': 0.516089721511217, 'MSE': 0.12756994742513755}\n"
     ]
    }
   ],
   "source": [
    "indicator=Indicator()\n",
    "\n",
    "y_true=np.array([0,1,0,1])\n",
    "y_pred=np.array([0,0,0,1])\n",
    "indicator.y_true.extend(y_true.tolist())\n",
    "indicator.y_pred.extend(y_pred.tolist())\n",
    "print(indicator.indicator_cls())\n",
    "indicator.reset()\n",
    "\n",
    "y_true=np.random.rand(10)\n",
    "y_pred=np.random.rand(10)\n",
    "indicator.y_true.extend(y_true.tolist())\n",
    "indicator.y_pred.extend(y_pred.tolist())\n",
    "print(indicator.indicator_reg())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "GOSE=np.load('/usr/commondata/weather/New/GOSE.npy',allow_pickle=True).item()\n",
    "StageIV=np.load('/usr/commondata/weather/New/StageIV.npy',allow_pickle=True).item()\n",
    "\n",
    "def date2num(start_date,end_dates):\n",
    "    result=[]\n",
    "    for T in end_dates:\n",
    "        end_date = date(int(T[:4]), int(T[4:6]), int(T[6:8]))\n",
    "        delta = (end_date - start_date)\n",
    "        day=delta.days\n",
    "        hour=T[8:]\n",
    "        result.append('{}.{}'.format(day,hour))\n",
    "    return result\n",
    "    \n",
    "start_date = date(2011, 12, 31)\n",
    "end_dates=list(StageIV.keys())\n",
    "StageIV_keys=date2num(start_date,end_dates)\n",
    "for i in range(len(StageIV_keys)):\n",
    "    StageIV[StageIV_keys[i]]=StageIV.pop(end_dates[i])\n",
    "\n",
    "\n",
    "balance=True\n",
    "if balance:\n",
    "    global_samples=np.load('/usr/commondata/weather/New/samples_B.npy')\n",
    "else:\n",
    "    global_samples=np.load('/usr/commondata/weather/New/samples.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class IRDataset(Dataset):\n",
    "    def __init__(self,mode='train',balance=True):\n",
    "        self.X=GOSE\n",
    "        self.Y=StageIV\n",
    "        self.samples=global_samples\n",
    "        \n",
    "        \n",
    "        L=len(self.samples)\n",
    "        self.mode=mode\n",
    "        if mode=='train':\n",
    "            self.sample_idx=range(0,int(L*0.6))\n",
    "        \n",
    "        if mode=='test':\n",
    "            self.sample_idx=range(int(L*0.6),int(L*0.8))\n",
    "        \n",
    "        if mode=='val':\n",
    "            self.sample_idx=range(int(L*0.8),int(L*1))\n",
    "        \n",
    "        self.L=len(self.sample_idx)\n",
    "    \n",
    "    \n",
    "    def crop_center(self,img,x,y,cropx,cropy):\n",
    "        startx = x-(cropx)\n",
    "        endx=x+(cropx)+1\n",
    "        starty = y-(cropy)   \n",
    "        endy= y+(cropy)+1  \n",
    "        \n",
    "        if len(img.shape)==3:\n",
    "            _,H,W=img.shape\n",
    "            if startx<0 or starty<0 or endx>=H or endy>=H:\n",
    "                return None\n",
    "            return img[:,startx:endx,starty:endy]\n",
    "            \n",
    "        if len(img.shape)==2:\n",
    "            H,W=img.shape\n",
    "            if startx<0 or starty<0 or endx>=H or endy>=H:\n",
    "                return None\n",
    "            return img[startx:endx,starty:endy]\n",
    "            \n",
    "    def sampling(self,key,img):\n",
    "        R_samples=[]\n",
    "        NR_samples=[]\n",
    "        for i in range(img.shape[0]):\n",
    "            for j in range(img.shape[1]):\n",
    "                Y=self.crop_center(img,i,j,14,14)\n",
    "                if Y is not None:\n",
    "                    if Y[14,14]>0.1:\n",
    "                        R_samples.append((key,i,j))\n",
    "                    else:\n",
    "                        NR_samples.append((key,i,j))\n",
    "        NR_samples_B=random.sample(NR_samples, len(R_samples))\n",
    "        return R_samples+NR_samples,R_samples+NR_samples_B\n",
    "    \n",
    "    \n",
    "    def get_samples(self):\n",
    "        useful_keys=list(set(self.X.keys())&set(self.Y.keys()))\n",
    "        self.useful_keys=sorted(useful_keys)\n",
    "        \n",
    "        samples=[]\n",
    "        samples_B=[]\n",
    "        for key in tqdm.tqdm(self.useful_keys):\n",
    "            samples_tmp,samples_B_tmp=self.sampling(key,self.Y[key])\n",
    "            samples+=samples_tmp\n",
    "            samples_B+=samples_B_tmp\n",
    "        return samples,samples_B\n",
    "    \n",
    "    def save_samples(self):\n",
    "        samples,samples_B=dataset.get_samples()\n",
    "        samples=np.array(samples)\n",
    "        samples_B=np.array(samples_B)\n",
    "        np.save('/usr/commondata/weather/New/samples_B.npy',samples_B)\n",
    "        np.save('/usr/commondata/weather/New/samples.npy',samples)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        key,i,j=self.samples[idx]\n",
    "        X,Y=self.X[key],self.Y[key]\n",
    "        i,j=int(i),int(j)\n",
    "        X_croped=self.crop_center(X,i,j,14,14)\n",
    "        Y_croped=self.crop_center(Y,i,j,14,14)\n",
    "        return X_croped,Y_croped,i,j,key\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.L\n",
    "\n",
    "    def name(self):\n",
    "        return 'IRDataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=IRDataset(mode='test',balance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data=np.array(list(GOSE.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[np.isnan(data)]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422.6626917616589 489.64054904540046\n",
      "442.8474696204027 1279.0312110649393\n",
      "442.8474696204027 1279.0312110649393\n",
      "-199.98306597322008 3892.523190931211\n",
      "442.8474696204027 1279.0312110649393\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    mean=np.mean(data[:,i,:,:])\n",
    "    var=np.var(data[:,i,:,:])\n",
    "    print(mean,var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(data[:,0,:,:]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
