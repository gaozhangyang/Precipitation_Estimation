{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Indicator\" data-toc-modified-id=\"Indicator-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Indicator</a></span></li><li><span><a href=\"#Dataloader\" data-toc-modified-id=\"Dataloader-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Dataloader</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Indicator:\n",
    "    def __init__(self):\n",
    "        self.y_true=[]\n",
    "        self.y_pred=[]\n",
    "        \n",
    "    def indicator_cls(self):\n",
    "        tn, fp, fn, tp=confusion_matrix(self.y_true,self.y_pred ).ravel()\n",
    "        POD=tp/(tp+fn)\n",
    "        FAR=fp/(tp+fp)\n",
    "        CSI=tp/(tp+fn+fp)\n",
    "        return {'POD':POD,'FAR':FAR,'CSI':CSI}\n",
    "    \n",
    "    def indicator_reg(self):\n",
    "        conv=np.cov([self.y_true,self.y_pred])\n",
    "        CC=conv[0,1]/np.sqrt(conv[0,0]*conv[1,1])\n",
    "        BIAS=np.sum(np.array(self.y_pred)-np.array(self.y_true))/np.sum(self.y_true)\n",
    "        MSE=np.mean((np.array(self.y_pred)-np.array(self.y_true))**2)\n",
    "        return {'CC':CC,'BIAS':BIAS,'MSE':MSE}\n",
    "    \n",
    "    def reset(self):\n",
    "        self.y_true=[]\n",
    "        self.y_pred=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POD': 0.5, 'FAR': 0.0, 'CSI': 0.5}\n",
      "{'CC': 0.5219991862216652, 'BIAS': -0.16938088345983845, 'MSE': 0.08807572443283634}\n"
     ]
    }
   ],
   "source": [
    "indicator=Indicator()\n",
    "\n",
    "y_true=np.array([0,1,0,1])\n",
    "y_pred=np.array([0,0,0,1])\n",
    "indicator.y_true.extend(y_true.tolist())\n",
    "indicator.y_pred.extend(y_pred.tolist())\n",
    "print(indicator.indicator_cls())\n",
    "indicator.reset()\n",
    "\n",
    "y_true=np.random.rand(10)\n",
    "y_pred=np.random.rand(10)\n",
    "indicator.y_true.extend(y_true.tolist())\n",
    "indicator.y_pred.extend(y_pred.tolist())\n",
    "print(indicator.indicator_reg())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T04:54:01.414440Z",
     "start_time": "2020-07-17T04:52:25.811472Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "GOSE=np.load('/usr/commondata/weather/New/WCE/GOSE.npy',allow_pickle=True).item()\n",
    "StageIV=np.load('/usr/commondata/weather/New/WCE/StageIV.npy',allow_pickle=True).item()\n",
    "\n",
    "def date2num(start_date,end_dates):\n",
    "    result=[]\n",
    "    for T in end_dates:\n",
    "        end_date = date(int(T[:4]), int(T[4:6]), int(T[6:8]))\n",
    "        delta = (end_date - start_date)\n",
    "        day=delta.days\n",
    "        hour=T[8:]\n",
    "        result.append('{}.{}'.format(day,hour))\n",
    "    return result\n",
    "    \n",
    "start_date = date(2011, 12, 31)\n",
    "end_dates=list(StageIV.keys())\n",
    "StageIV_keys=date2num(start_date,end_dates)\n",
    "for i in range(len(StageIV_keys)):\n",
    "    StageIV[StageIV_keys[i]]=StageIV.pop(end_dates[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T05:29:23.292591Z",
     "start_time": "2020-07-17T05:28:58.169089Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1376/1376 [00:25<00:00, 54.78it/s]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "f = h5py.File('./test.nc',mode = 'w')\n",
    "for key in tqdm.tqdm(GOSE.keys()):\n",
    "    f.create_dataset(key,data = GOSE[key],compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class IRDataset(Dataset):\n",
    "    def __init__(self,task='identification',mode='train',balance=True):\n",
    "        self.X=GOSE\n",
    "        self.Y=StageIV\n",
    "        \n",
    "        \n",
    "        if not os.path.exists('/usr/commondata/weather/New/WCE/R_samples.npy'):\n",
    "            R_samples,NR_samples=self.get_samples(GOSE,StageIV)\n",
    "            self.save_samples(R_samples,NR_samples)\n",
    "        \n",
    "        self.R_samples=np.load('/usr/commondata/weather/New/WCE/R_samples.npy')\n",
    "        self.NR_samples=np.load('/usr/commondata/weather/New/WCE/NR_samples.npy')\n",
    "        \n",
    "        \n",
    "        if task=='identification':\n",
    "            R_samples=np.array(random.choices(self.R_samples,k=340000))\n",
    "            NR_samples=np.array(random.choices(self.NR_samples,k=340000))\n",
    "        \n",
    "        if task=='estimation':\n",
    "            R_samples=np.array(random.choices(self.R_samples,k=340000))\n",
    "            NR_samples=np.array(random.choices(self.NR_samples,k=340000))\n",
    "        \n",
    "        self.samples=np.vstack([R_samples,NR_samples])\n",
    "        np.random.shuffle(self.samples)\n",
    "        L=len(self.samples)\n",
    "        \n",
    "        \n",
    "        self.mode=mode\n",
    "        if mode=='train':\n",
    "            self.sample_idx=range(0,int(L*0.6))\n",
    "        \n",
    "        if mode=='test':\n",
    "            self.sample_idx=range(int(L*0.6),int(L*0.8))\n",
    "        \n",
    "        if mode=='val':\n",
    "            self.sample_idx=range(int(L*0.8),int(L*1))\n",
    "        \n",
    "        self.L=len(self.sample_idx)\n",
    "        \n",
    "        \n",
    "        self.mean=np.array([407.1981814386521,905.3917506083453,1041.6140561764744]).reshape(-1,1)\n",
    "        self.std_var=np.sqrt(np.array([412.5176029578715,20423.3857524064,16250.988775375401])).reshape(-1,1)\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def crop_center(self,img,x,y,cropx,cropy):\n",
    "        startx = x-(cropx)\n",
    "        endx=x+(cropx)+1\n",
    "        starty = y-(cropy)   \n",
    "        endy= y+(cropy)+1  \n",
    "        \n",
    "        if len(img.shape)==3:\n",
    "            _,H,W=img.shape\n",
    "            if startx<0 or starty<0 or endx>=H or endy>=H:\n",
    "                return None\n",
    "            return img[:,startx:endx,starty:endy]\n",
    "            \n",
    "        if len(img.shape)==2:\n",
    "            H,W=img.shape\n",
    "            if startx<0 or starty<0 or endx>=H or endy>=H:\n",
    "                return None\n",
    "            return img[startx:endx,starty:endy]\n",
    "    \n",
    "    @classmethod\n",
    "    def sampling(self,key,img):\n",
    "        R_samples=[]\n",
    "        NR_samples=[]\n",
    "        for i in range(0,img.shape[0],15):\n",
    "            for j in range(0,img.shape[1],15):\n",
    "                Y=self.crop_center(img,i,j,14,14)\n",
    "                if Y is not None:\n",
    "                    if Y[14,14]>0.1:\n",
    "                        R_samples.append((key,i,j))\n",
    "                    else:\n",
    "                        NR_samples.append((key,i,j))\n",
    "        return R_samples,NR_samples\n",
    "    \n",
    "    @classmethod\n",
    "    def get_samples(self,GOSE,StageIV):\n",
    "        useful_keys=list(set(GOSE.keys())&set(StageIV.keys()))\n",
    "        useful_keys=sorted(useful_keys)\n",
    "        \n",
    "        R_samples=[]\n",
    "        NR_samples=[]\n",
    "        for key in tqdm.tqdm(useful_keys):\n",
    "            R_samples_tmp,NR_samples_tmp=self.sampling(key,StageIV[key])\n",
    "            R_samples+=R_samples_tmp\n",
    "            NR_samples+=NR_samples_tmp\n",
    "        return R_samples,NR_samples\n",
    "    \n",
    "    @classmethod\n",
    "    def save_samples(self,R_samples,NR_samples):\n",
    "        R_samples=np.array(R_samples)\n",
    "        NR_samples=np.array(NR_samples)\n",
    "        np.save('/usr/commondata/weather/New/WCE/R_samples.npy',R_samples)\n",
    "        np.save('/usr/commondata/weather/New/WCE/NR_samples.npy',NR_samples)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        key,i,j=self.samples[idx]\n",
    "        X,Y=self.X[key],self.Y[key]\n",
    "        i,j=int(i),int(j)\n",
    "        X_croped=self.crop_center(X,i,j,14,14)\n",
    "        Y_croped=Y[i,j]\n",
    "        for chennel in range(3):\n",
    "            X_croped[chennel,:,:]=(X_croped[chennel,:,:]-self.mean[chennel])/self.std_var[chennel]\n",
    "        return X_croped,Y_croped,i,j,key\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.L\n",
    "\n",
    "    def name(self):\n",
    "        return 'IRDataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=IRDataset(mode='test',balance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5649999998435"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_croped,Y_croped,i,j,key=dataset[4]\n",
    "Y_croped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407.1981814386521 412.5176029578715\n",
      "905.3917506083453 20423.3857524064\n",
      "1041.6140561764744 16250.988775375401\n"
     ]
    }
   ],
   "source": [
    "data=np.array(list(GOSE.values()))\n",
    "data[np.isnan(data)]=0\n",
    "for i in range(0,3):\n",
    "    mean=np.mean(data[:,i,:,:])\n",
    "    var=np.var(data[:,i,:,:])\n",
    "    print(mean,var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
